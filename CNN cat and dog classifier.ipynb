{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44de898d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.5 | packaged by Anaconda, Inc. | (main, Sep 11 2023, 13:26:23) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b09ce628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70641754",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77d29f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1/255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4341b1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8047 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory(\"C:\\\\Users\\\\DIVYA\\\\dataset-20241201T091701Z-001\\\\dataset\\\\training_set\",\n",
    "                                                 target_size=(64,64),\n",
    "                                                 class_mode=\"binary\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "382ca066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cats': 0, 'dogs': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bad4c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8047 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1/255)\n",
    "test_set=test_datagen.flow_from_directory(\"C:\\\\Users\\\\DIVYA\\\\dataset-20241201T091701Z-001\\\\dataset\\\\training_set\",\n",
    "                                                 target_size=(64,64),\n",
    "                                                 class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c249d205",
   "metadata": {},
   "source": [
    "# Modelling-Convolution Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2187b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66808d5",
   "metadata": {},
   "source": [
    "**step-1-Convolution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42c74076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DIVYA\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D \n",
    "classifier.add(Conv2D(input_shape=[64,64,3],filters=32, kernel_size=3, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d773d52",
   "metadata": {},
   "source": [
    "**Step-2-Max Pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f611e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D\n",
    "classifier.add(MaxPooling2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5689026b",
   "metadata": {},
   "source": [
    "**Step-3-Flattening**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ae5b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aebd25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d050fa7f",
   "metadata": {},
   "source": [
    "**Step-4-Full connection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f57d79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "# hidden layer with 128  neuron\n",
    "classifier.add(Dense(units=128,activation=\"relu\"))\n",
    "\n",
    "\n",
    "#Output layers with  neuron\n",
    "classifier.add(Dense(units=1,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11a095e",
   "metadata": {},
   "source": [
    "**Training the CNN Model with train data & Testing the model with test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0277938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer=\"adam\",\n",
    "                   loss=\"binary_crossentropy\",\n",
    "                   metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70a6fe7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DIVYA\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 336ms/step - accuracy: 0.5411 - loss: 0.8490"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DIVYA\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 491ms/step - accuracy: 0.5413 - loss: 0.8484 - val_accuracy: 0.6887 - val_loss: 0.6081\n",
      "Epoch 2/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 423ms/step - accuracy: 0.6641 - loss: 0.6187 - val_accuracy: 0.7172 - val_loss: 0.5559\n",
      "Epoch 3/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 424ms/step - accuracy: 0.7010 - loss: 0.5702 - val_accuracy: 0.7047 - val_loss: 0.5581\n",
      "Epoch 4/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 436ms/step - accuracy: 0.7113 - loss: 0.5552 - val_accuracy: 0.7502 - val_loss: 0.5025\n",
      "Epoch 5/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 419ms/step - accuracy: 0.7409 - loss: 0.5252 - val_accuracy: 0.7655 - val_loss: 0.4894\n",
      "Epoch 6/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 420ms/step - accuracy: 0.7466 - loss: 0.5136 - val_accuracy: 0.7497 - val_loss: 0.5053\n",
      "Epoch 7/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 422ms/step - accuracy: 0.7515 - loss: 0.4999 - val_accuracy: 0.7850 - val_loss: 0.4576\n",
      "Epoch 8/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 422ms/step - accuracy: 0.7555 - loss: 0.4968 - val_accuracy: 0.7697 - val_loss: 0.4794\n",
      "Epoch 9/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 452ms/step - accuracy: 0.7705 - loss: 0.4803 - val_accuracy: 0.8015 - val_loss: 0.4298\n",
      "Epoch 10/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 434ms/step - accuracy: 0.7859 - loss: 0.4562 - val_accuracy: 0.8142 - val_loss: 0.4045\n",
      "Epoch 11/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m222s\u001b[0m 883ms/step - accuracy: 0.7939 - loss: 0.4447 - val_accuracy: 0.8059 - val_loss: 0.4268\n",
      "Epoch 12/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 611ms/step - accuracy: 0.7860 - loss: 0.4583 - val_accuracy: 0.7630 - val_loss: 0.4845\n",
      "Epoch 13/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 514ms/step - accuracy: 0.7998 - loss: 0.4344 - val_accuracy: 0.8342 - val_loss: 0.3676\n",
      "Epoch 14/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 500ms/step - accuracy: 0.8099 - loss: 0.4150 - val_accuracy: 0.8347 - val_loss: 0.3671\n",
      "Epoch 15/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 503ms/step - accuracy: 0.8152 - loss: 0.4117 - val_accuracy: 0.8453 - val_loss: 0.3546\n",
      "Epoch 16/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 556ms/step - accuracy: 0.8149 - loss: 0.4031 - val_accuracy: 0.8442 - val_loss: 0.3580\n",
      "Epoch 17/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 467ms/step - accuracy: 0.8245 - loss: 0.3874 - val_accuracy: 0.8541 - val_loss: 0.3405\n",
      "Epoch 18/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m264s\u001b[0m 1s/step - accuracy: 0.8268 - loss: 0.3836 - val_accuracy: 0.8476 - val_loss: 0.3487\n",
      "Epoch 19/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 467ms/step - accuracy: 0.8286 - loss: 0.3746 - val_accuracy: 0.8667 - val_loss: 0.3122\n",
      "Epoch 20/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 539ms/step - accuracy: 0.8399 - loss: 0.3559 - val_accuracy: 0.8700 - val_loss: 0.3088\n",
      "Epoch 21/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 625ms/step - accuracy: 0.8415 - loss: 0.3528 - val_accuracy: 0.8760 - val_loss: 0.2904\n",
      "Epoch 22/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 1s/step - accuracy: 0.8434 - loss: 0.3450 - val_accuracy: 0.8884 - val_loss: 0.2706\n",
      "Epoch 23/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 510ms/step - accuracy: 0.8445 - loss: 0.3400 - val_accuracy: 0.8724 - val_loss: 0.2952\n",
      "Epoch 24/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 223ms/step - accuracy: 0.8619 - loss: 0.3173 - val_accuracy: 0.8770 - val_loss: 0.2891\n",
      "Epoch 25/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 262ms/step - accuracy: 0.8576 - loss: 0.3249 - val_accuracy: 0.8783 - val_loss: 0.2882\n",
      "Epoch 26/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 217ms/step - accuracy: 0.8604 - loss: 0.3137 - val_accuracy: 0.8960 - val_loss: 0.2517\n",
      "Epoch 27/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 236ms/step - accuracy: 0.8648 - loss: 0.3102 - val_accuracy: 0.8969 - val_loss: 0.2509\n",
      "Epoch 28/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 242ms/step - accuracy: 0.8798 - loss: 0.2836 - val_accuracy: 0.9031 - val_loss: 0.2403\n",
      "Epoch 29/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 230ms/step - accuracy: 0.8747 - loss: 0.2863 - val_accuracy: 0.8959 - val_loss: 0.2496\n",
      "Epoch 30/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 246ms/step - accuracy: 0.8792 - loss: 0.2808 - val_accuracy: 0.8690 - val_loss: 0.3138\n",
      "Epoch 31/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 266ms/step - accuracy: 0.8798 - loss: 0.2793 - val_accuracy: 0.9249 - val_loss: 0.1892\n",
      "Epoch 32/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 262ms/step - accuracy: 0.8824 - loss: 0.2720 - val_accuracy: 0.9067 - val_loss: 0.2312\n",
      "Epoch 33/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 249ms/step - accuracy: 0.8883 - loss: 0.2612 - val_accuracy: 0.9251 - val_loss: 0.1885\n",
      "Epoch 34/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 242ms/step - accuracy: 0.8972 - loss: 0.2510 - val_accuracy: 0.9085 - val_loss: 0.2204\n",
      "Epoch 35/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 238ms/step - accuracy: 0.8902 - loss: 0.2512 - val_accuracy: 0.8741 - val_loss: 0.2898\n",
      "Epoch 36/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 244ms/step - accuracy: 0.8926 - loss: 0.2498 - val_accuracy: 0.9280 - val_loss: 0.1767\n",
      "Epoch 37/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 274ms/step - accuracy: 0.9019 - loss: 0.2362 - val_accuracy: 0.9254 - val_loss: 0.1817\n",
      "Epoch 38/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 284ms/step - accuracy: 0.9054 - loss: 0.2218 - val_accuracy: 0.9315 - val_loss: 0.1712\n",
      "Epoch 39/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 258ms/step - accuracy: 0.9083 - loss: 0.2202 - val_accuracy: 0.9436 - val_loss: 0.1432\n",
      "Epoch 40/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 275ms/step - accuracy: 0.9086 - loss: 0.2130 - val_accuracy: 0.9402 - val_loss: 0.1564\n",
      "Epoch 41/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 267ms/step - accuracy: 0.9133 - loss: 0.2130 - val_accuracy: 0.9201 - val_loss: 0.1938\n",
      "Epoch 42/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 261ms/step - accuracy: 0.9215 - loss: 0.1961 - val_accuracy: 0.9391 - val_loss: 0.1550\n",
      "Epoch 43/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 257ms/step - accuracy: 0.9211 - loss: 0.1937 - val_accuracy: 0.9420 - val_loss: 0.1430\n",
      "Epoch 44/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 298ms/step - accuracy: 0.9237 - loss: 0.1862 - val_accuracy: 0.9364 - val_loss: 0.1635\n",
      "Epoch 45/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 259ms/step - accuracy: 0.9191 - loss: 0.1978 - val_accuracy: 0.9555 - val_loss: 0.1220\n",
      "Epoch 46/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 285ms/step - accuracy: 0.9274 - loss: 0.1845 - val_accuracy: 0.9289 - val_loss: 0.1660\n",
      "Epoch 47/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 269ms/step - accuracy: 0.9301 - loss: 0.1764 - val_accuracy: 0.9474 - val_loss: 0.1315\n",
      "Epoch 48/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 302ms/step - accuracy: 0.9321 - loss: 0.1685 - val_accuracy: 0.9576 - val_loss: 0.1072\n",
      "Epoch 49/50\n",
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 283ms/step - accuracy: 0.9363 - loss: 0.1702 - val_accuracy: 0.9527 - val_loss: 0.1194\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m252/252\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 249ms/step - accuracy: 0.9219 - loss: 0.1780 - val_accuracy: 0.9638 - val_loss: 0.1007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x221177f4450>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(\n",
    "    x=training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827cfd37",
   "metadata": {},
   "source": [
    "# Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c37362",
   "metadata": {},
   "source": [
    "##### Making a single prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "005c8530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3f9bd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 638ms/step\n",
      "Cat\n"
     ]
    }
   ],
   "source": [
    "#load the data\n",
    "test_image = Image.open(r\"C:\\Users\\DIVYA\\OneDrive\\Desktop\\cat img.jpg\")\n",
    "\n",
    "# Data preprocessing\n",
    "test_image=test_image.resize((64,64))\n",
    "test_image=np.array(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "\n",
    "#Prediction\n",
    "result=classifier.predict(test_image)\n",
    "\n",
    "#Evaluation\n",
    "if result[0][0]==1:\n",
    "    print(\"Dog\")\n",
    "else:\n",
    "    print(\"Cat\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b2ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
